{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# **Easy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScrapingEasy:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "    def cleanPath(self):\n",
    "        txt = self.path.lower().split(' > ')\n",
    "        txt = [i.replace(' ', '-') for i in txt]\n",
    "        txt = '/'.join(txt)\n",
    "        txt = txt.replace('ñ', 'n')\n",
    "        txt = re.sub(r'[àáâãäå]', 'a', txt)\n",
    "        txt = re.sub(r'[èéêë]'  , 'e', txt)\n",
    "        txt = re.sub(r'[ìíîï]'  , 'i', txt)\n",
    "        txt = re.sub(r'[òóôõö]' , 'o', txt)\n",
    "        txt = re.sub(r'[ùúûü]'  , 'u', txt)\n",
    "        return txt\n",
    "    def getValues(self, Soup):\n",
    "        Titulos = Soup.find_all('div', attrs = {'class' : 'dpr_product-name'})\n",
    "        Titulos = [i.text for i in Titulos]\n",
    "        Precios = Soup.find_all('div', attrs = {'class' : 'dpr_listprice'})\n",
    "        Precios = [i.text for i in Precios]\n",
    "        Precios = [i.replace('$', '') for i in Precios]\n",
    "        Precios = [i.replace(',', '.') for i in Precios]\n",
    "        URLs = Soup.find_all('a', attrs = {'class' : 'dpr_listname'})\n",
    "        URLs = [i.get('href') for i in URLs]\n",
    "        URLs = ['https://www.easy.com.co' + i for i in URLs]\n",
    "        return Titulos, Precios, URLs\n",
    "    def createDF(self, Titles, Prices, URLs):\n",
    "        df = pd.DataFrame({'URL': URLs, 'Producto': Titles, 'Precio': Prices})\n",
    "        df['Origen'] = \"Easy\"\n",
    "        df.to_csv('Support Files/Easy.csv', index = False)\n",
    "        df.to_csv('Support Files/Easy.txt', sep = '|', index = False)\n",
    "        return df\n",
    "    def controller(self):\n",
    "        Website = 'https://www.easy.com.co/c/'+self.cleanPath()+'/'\n",
    "        listTitulos = []\n",
    "        listPrecios = []\n",
    "        listURLs = []\n",
    "        j = 1\n",
    "        while True:\n",
    "            print(f\"Página Número: {j} | Link: {Website}\")\n",
    "            Result  = requests.get(Website)\n",
    "            if Result.status_code == 200:\n",
    "                Content = Result.content\n",
    "                Soup = BeautifulSoup(Content, 'html.parser') # 'lxml'\n",
    "                # print(Soup.prettify())\n",
    "                Dom  = etree.HTML(str(Soup))\n",
    "                Next = Dom.xpath('//div[@class = \"top-listado-producto pr\"][1]/div[@class = \"paginador\"]/div[@class = \"page_nav_grid\"]/ul/li/a')\n",
    "                Titulos, Precios, URLs = self.getValues(Soup)\n",
    "                listTitulos.extend(Titulos)\n",
    "                listPrecios.extend(Precios)\n",
    "                listURLs.extend(URLs)\n",
    "                if Next == []:\n",
    "                    break\n",
    "                else:\n",
    "                    if j == 1:\n",
    "                        # nStart = int(Next[0].text)\n",
    "                        nEnd   = int(Next[-2].text)\n",
    "                        # print(nStart, nEnd)\n",
    "                    if j == nEnd:\n",
    "                        break\n",
    "                    j += 1\n",
    "                    Website = 'https://www.easy.com.co'+Next[-1].get('href')\n",
    "            else:\n",
    "                print(f\"Sin respuesta por parte del servidor. Fallo al tratar de visitar la página web:\\n\\t--> {Website}\"\n",
    "                )\n",
    "                break\n",
    "        return self.createDF(listTitulos, listPrecios, listURLs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# **Homecenter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScrapingHomeCenter:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "    def getCategories(self):\n",
    "        filePath = 'Code/CategoriesList_HomeCenter.pkl'\n",
    "        if os.path.isfile(filePath) == False:\n",
    "            print(\n",
    "                \"En el directorio no se encuentra el archivo:\\n\\\n",
    "                \\tCategoriesList_HomeCenter.pkl\"\n",
    "            )\n",
    "        else:\n",
    "            return pd.read_pickle(\"Code/CategoriesList_HomeCenter.pkl\")\n",
    "    def checkStatus(self, url):\n",
    "        try:\n",
    "            Result = requests.get(url)\n",
    "            status = \"Conexión Valida\" if Result.status_code == 200 else \"Conexión sin Respuesta\"\n",
    "        except:\n",
    "            status = \"Conexión sin Respuesta\"\n",
    "        hora = (datetime.now()).strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        return (status, hora)\n",
    "    def updateURL(self, df, all):\n",
    "        if all:\n",
    "            df['infoStatus'] = df['URL'].apply(self.checkStatus)\n",
    "            df[['Status', 'Status_Date']] = pd.DataFrame(\n",
    "                df['infoStatus'].tolist(), index = df.index\n",
    "            )\n",
    "            df.drop(['infoStatus'], axis = 1, inplace = True)\n",
    "            print(\"___________________________________________________________\")\n",
    "        else:\n",
    "            newURL = input(\n",
    "                f\"Ingrese la nueva URL para la categoría: {self.path}\"\n",
    "            )\n",
    "            x = self.checkStatus(newURL)\n",
    "            df.loc[df[\"Categoria\"] == self.path, ['URL', 'Status', 'Status_Date']] = [newURL, x[0], x[1]]\n",
    "        df.to_pickle(\"Code/CategoriesList_HomeCenter.pkl\")\n",
    "    def addCategories(self, df):\n",
    "        Input_Cat = self.path\n",
    "        Input_URL = input(\"Ingrese la URL de la nueva categoría: \")\n",
    "        newRow = {\n",
    "            'Categoria'  : Input_Cat,\n",
    "            'URL'        : Input_URL,\n",
    "            'Status'     : 'Nueva Categoría',\n",
    "            'Status_Date': (datetime.now()).strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        }\n",
    "        df = df.append(newRow, ignore_index = True)\n",
    "        df.to_pickle(\"Code/CategoriesList_HomeCenter.pkl\")\n",
    "        return Input_URL\n",
    "    def getValues(self, Soup, Dom):\n",
    "        Titulos = Soup.find_all('h2', attrs = {'class' : 'jsx-2974854745 product-title'})\n",
    "        if Titulos == []:\n",
    "            Titulos = Soup.find_all('div', attrs = {'class' : 'jsx-110785930 title-name'})\n",
    "        Titulos = [i.text for i in Titulos]\n",
    "\n",
    "        Precios = Dom.xpath('//div[@class = \"jsx-2974854745 desktop-price-cart-btn\"]//div[contains(@class, \"jsx-344173702 main\")]/div[@class = \"jsx-4135487716 price jsx-175035124\"]/span[@class = \"jsx-4135487716\"]')\n",
    "        if Precios == []:\n",
    "            Precios = Dom.xpath('//div[@class = \"jsx-110785930 price-container\"]//div[contains(@class, \"jsx-344173702 main\")]/div[@class = \"jsx-4135487716 price jsx-175035124\"]/span[@class = \"jsx-4135487716\"]')\n",
    "        Precios = [i.text for i in Precios]\n",
    "        Precios = [i.replace('$', '') for i in Precios]\n",
    "\n",
    "        URLs = Soup.find_all('a', attrs = {'class' : 'jsx-2974854745'})\n",
    "        if URLs == []:\n",
    "            URLs = Soup.find_all('a', attrs = {'id' : 'testId-Link-title-pdp-link'})\n",
    "        URLs = [i.get('href') for i in URLs]\n",
    "        URLs = ['https://www.homecenter.com.co' + i for i in URLs]\n",
    "        if len(Titulos) == len(Precios) == len(URLs):\n",
    "            return Titulos, Precios, URLs\n",
    "        else:\n",
    "            print(\n",
    "                f'''\n",
    "                La longitud de los tres arreglos no coincide:\n",
    "                \\t--> Titulos tiene una longitud de {len(Titulos)}\n",
    "                \\t--> Precios tiene una longitud de {len(Precios)}\n",
    "                \\t--> URLs tiene una longitud de {len(URLs)}\n",
    "                '''\n",
    "            )\n",
    "    def createDF(self, Titles, Prices, URLs):\n",
    "        df = pd.DataFrame({'URL': URLs, 'Producto': Titles, 'Precio': Prices})\n",
    "        df['Origen'] = \"HomeCenter\"\n",
    "        df.to_csv('Support Files/HomeCenter.csv', index = False)\n",
    "        df.to_csv('Support Files/HomeCenter.txt', sep = '|', index = False)\n",
    "        return df\n",
    "    def controller(self):\n",
    "        df = self.getCategories()\n",
    "        # Monday = 0 | Sunday = 6\n",
    "        if (datetime.now()).weekday() == -1:\n",
    "            print(\n",
    "                \"Hoy se realizará la actualización del status de las conexiones\\\n",
    "                \\nEsto puede tomar un tiempo, por favor espere ...\"\n",
    "            )\n",
    "            self.updateURL(df, all = True)\n",
    "            print('¡Actualización finalizada con éxito!')\n",
    "        # ----------------------------------------------------------------------\n",
    "        try:\n",
    "            Website = df[df['Categoria'].str.lower() == self.path.lower()]['URL'].values[0]\n",
    "            if self.checkStatus(Website)[0] == \"Conexión sin Respuesta\":\n",
    "                self.updateURL(df, all = False)\n",
    "                Website = df[df['Categoria'].str.lower() == self.path.lower()]['URL'].values[0]\n",
    "        except:\n",
    "            Website = self.addCategories(df)\n",
    "        print(Website)\n",
    "        listTitulos = []\n",
    "        listPrecios = []\n",
    "        listURLs = []\n",
    "        j = 1\n",
    "        while True:\n",
    "            print(f\"Página Número: {j} | Link: {Website}\")\n",
    "            Result = requests.get(Website)\n",
    "            if Result.status_code == 200:\n",
    "                Content = Result.content\n",
    "                Soup = BeautifulSoup(Content, 'html.parser')\n",
    "                Dom  = etree.HTML(str(Soup))\n",
    "\n",
    "                Titulos, Precios, URLs = self.getValues(Soup, Dom)\n",
    "                listTitulos.extend(Titulos)\n",
    "                listPrecios.extend(Precios)\n",
    "                listURLs.extend(URLs)\n",
    "\n",
    "                Next = Dom.xpath('//div[@class = \"jsx-861649955 tablet-desktop media-component\"]//div[@class = \"jsx-4278284191 scroll-area\"]//button[@class = \"jsx-4278284191\"]')\n",
    "                Next = [int(i.text) for i in Next]\n",
    "                if Next == []:\n",
    "                    break\n",
    "                else:\n",
    "                    if j == 1:\n",
    "                        nEnd = max(Next)\n",
    "                        base = re.sub(r\".$\", \"?currentpage=\", Website)\n",
    "                    if j == nEnd:\n",
    "                        break\n",
    "                    j += 1\n",
    "                    Website = base + str(j)\n",
    "            else:\n",
    "                print(f\"Sin respuesta por parte del servidor. Fallo al tratar de visitar la página web:\\n\\t--> {Website}\"\n",
    "                )\n",
    "                break\n",
    "        return self.createDF(listTitulos, listPrecios, listURLs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# **Mercado Libre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScrapingMercadoLibre:\n",
    "    def __init__(self, product, limit, infoExtra):\n",
    "        self.product   = product\n",
    "        self.limit     = limit\n",
    "        self.infoExtra = infoExtra\n",
    "    def cleanPath(self):\n",
    "        txt = self.product.lower()\n",
    "        txt = txt.replace(' ', '-')\n",
    "        txt = txt.replace('ñ', 'n')\n",
    "        txt = re.sub(r'[àáâãäå]', 'a', txt)\n",
    "        txt = re.sub(r'[èéêë]'  , 'e', txt)\n",
    "        txt = re.sub(r'[ìíîï]'  , 'i', txt)\n",
    "        txt = re.sub(r'[òóôõö]' , 'o', txt)\n",
    "        txt = re.sub(r'[ùúûü]'  , 'u', txt)\n",
    "        return txt\n",
    "    def getInfoExtra(self, URL):\n",
    "        Result = requests.get(URL)\n",
    "        if Result.status_code == 200:\n",
    "            Content = Result.content\n",
    "            Soup = BeautifulSoup(Content, 'html.parser')\n",
    "            Dom  = etree.HTML(str(Soup))\n",
    "\n",
    "            Path = Soup.find_all('a', attrs = {'class' : 'andes-breadcrumb__link'})\n",
    "            Path   = [i.text for i in Path]\n",
    "            Path   = ' > '.join(Path)\n",
    "            Trade  = Soup.find('span', attrs = {'class' : 'ui-pdp-subtitle'})\n",
    "            Trade  = int(re.findall(r'\\d+', Trade.text)[0])\n",
    "            # X = Soup.find('p', attrs = {'class' : 'ui-review-capability__rating__average ui-review-capability__rating__average--desktop'})\n",
    "            Rating = Dom.xpath('//p[contains(@class, \"ui-review-capability__rating__average\")]')\n",
    "            try:\n",
    "                Rating = [float(i.text) for i in Rating][0]\n",
    "            except:\n",
    "                Rating = np.nan\n",
    "            Envio = Dom.xpath('//p[contains(@class, \"ui-pdp-color--GREEN ui-pdp-family--REGULAR ui-pdp-media__title\")]')\n",
    "            Envio = [i.text for i in Envio]\n",
    "            if Envio != []:\n",
    "                Envio = True if Envio != ['Paga en cuotas sin interés'] else False\n",
    "            else:\n",
    "                Envio = False\n",
    "\n",
    "            return Path, Rating, Trade, Envio\n",
    "        else:\n",
    "            print(f'Página del producto en cuestión NO encontrada, no se retorna información extra de este\\nURL: {URL}')\n",
    "            return np.nan, np.nan, np.nan, False\n",
    "    def getValues(self, Soup, Dom):\n",
    "        Titulos = Soup.find_all('h2', attrs = {'class' : 'ui-search-item__title shops__item-title'})\n",
    "        Titulos = [i.text for i in Titulos]\n",
    "        Precios = Dom.xpath('//div[@class = \"ui-search-price ui-search-price--size-medium shops__price\"]//div[@class = \"ui-search-price__second-line shops__price-second-line\"]//span[@class = \"price-tag-amount\"]/span[2]')\n",
    "        Precios = [i.text for i in Precios]\n",
    "        URLs = Soup.find_all('a', attrs = {'class' : 'ui-search-item__group__element shops__items-group-details ui-search-link'})\n",
    "        URLs = [i.get('href') for i in URLs]\n",
    "        return Titulos, Precios, URLs\n",
    "    def createDF(self, Titles, Prices, URLs):\n",
    "        df = pd.DataFrame({'URL': URLs, 'Producto': Titles, 'Precio': Prices})\n",
    "        df['Origen'] = \"Mercado Libre\"\n",
    "        df.to_csv('Support Files/MercadoLibre.csv', index = False)\n",
    "        df.to_csv('Support Files/MercadoLibre.txt', sep = '|', index = False)\n",
    "        return df\n",
    "    def controller(self):\n",
    "        Website = 'https://listado.mercadolibre.com.co/' + self.cleanPath()\n",
    "        listTitulos = []\n",
    "        listPrecios = []\n",
    "        listURLs = []\n",
    "        while True:\n",
    "            Result  = requests.get(Website)\n",
    "            if Result.status_code == 200:\n",
    "                Content = Result.content\n",
    "                Soup = BeautifulSoup(Content, 'html.parser')\n",
    "                Dom  = etree.HTML(str(Soup))\n",
    "\n",
    "                Titulos, Precios, URLs = self.getValues(Soup, Dom)\n",
    "                listTitulos.extend(Titulos)\n",
    "                listPrecios.extend(Precios)\n",
    "                listURLs.extend(URLs)\n",
    "\n",
    "                nStart = int(\n",
    "                    Soup.find('span', attrs = {\"class\" : \"andes-pagination__link\"}).text\n",
    "                )\n",
    "                nEnd = Soup.find('li', attrs = {\"class\" : \"andes-pagination__page-count\"})\n",
    "                nEnd = int(\n",
    "                    nEnd.text.split(\" \")[1]\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Sin respuesta por parte del servidor. Fallo al tratar de visitar la página web:\\n\\t--> {Website}\"\n",
    "                )\n",
    "                break\n",
    "            print(f\"Visitando la Página Número: {nStart} de {nEnd}\")\n",
    "            print(f\"Link: {Website}\")\n",
    "            if len(listTitulos) >= int(self.limit):\n",
    "                df = self.createDF(\n",
    "                    listTitulos[:self.limit],\n",
    "                    listPrecios[:self.limit],\n",
    "                    listURLs[:self.limit]\n",
    "                )\n",
    "                if self.infoExtra:\n",
    "                    df['Tuple'] = df['URL'].apply(self.getInfoExtra)\n",
    "                    df[['Categoria', 'Ranting', 'Vendidos', 'EnvíoGratis']] = pd.DataFrame(df['Tuple'].tolist(), index = df.index)\n",
    "                    df.drop(['Tuple'], axis = 1, inplace = True)\n",
    "                    df.to_csv('Support Files/MercadoLibre.csv', index = False)\n",
    "                    df.to_csv('Support Files/MercadoLibre.txt', sep = '|', index = False)\n",
    "                return df\n",
    "            if nStart == nEnd:\n",
    "                break\n",
    "            Website = Dom.xpath('//div[@class=\"ui-search-pagination shops__pagination-content\"]/ul/li[contains(@class,\"--next\")]/a')[0].get('href')\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# **AliExpress**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebScrapingAliExpress:\n",
    "    def __init__(self, product, limit):\n",
    "        self.product = product\n",
    "        self.limit   = limit\n",
    "    def cleanPath(self):\n",
    "        txt = self.product.lower()\n",
    "        txt = txt.replace(' ', '+')\n",
    "        txt = txt.replace('ñ', 'n')\n",
    "        txt = re.sub(r'[àáâãäå]', 'a', txt)\n",
    "        txt = re.sub(r'[èéêë]'  , 'e', txt)\n",
    "        txt = re.sub(r'[ìíîï]'  , 'i', txt)\n",
    "        txt = re.sub(r'[òóôõö]' , 'o', txt)\n",
    "        txt = re.sub(r'[ùúûü]'  , 'u', txt)\n",
    "        return txt\n",
    "    def getConnection(self, search, page):\n",
    "        url    = \"https://es.aliexpress.com/glosearch/api/product\"\n",
    "        urlRaw = 'https://es.aliexpress.com/wholesale?trafficChannel=ppc&d=y&CatId=0&SearchText={}&ltype=premium&SortType=default&page={}'.format(search, page)\n",
    "        query_string_parameters = {\n",
    "            'trafficChannel' : 'ppc'    ,\n",
    "            'd'              : 'y'      ,\n",
    "            'CatId'          : '0'      ,\n",
    "            'SearchText'     : search   ,\n",
    "            'ltype'          : 'premium',\n",
    "            'SortType'       : 'default',\n",
    "            'page'           : str(page),\n",
    "            'origin'         : 'y'\n",
    "        }\n",
    "        headers = {\n",
    "            'accept': 'application/json, text/plain, */*',\n",
    "            'accept-encoding': 'gzip, deflate, br',\n",
    "            'accept-language': 'es-419,es;q=0.9',\n",
    "            'bx-v': '2.2.3',\n",
    "            'cookie': 'acs_usuc_t=x_csrf=1e83jkp1mo0xf&acs_rt=bc33d50efba94b6fb9b8abfdd1ed9ba6; aeu_cid=6afa8bad078e42a0ba2674ea27a0dc7f-1669256183899-05653-UneMJZVf; xman_t=3tn7B9rqQ8sVaohEod6BPWSDslwwzGlfOVRP0Jhf097sZL4o4wkHoTKRc1iE6pFN; xman_f=umZ8TL4zuB6Cu7fs8HRdn8t0FY8crEiG5MlWTkMhCZsM+AQGWBmKzL9nZEq42c8c2beLnRypHNPhITo1KZMsSJ7p0lL+uQPq9aD/GQ1YcuQXGF3QHc9lBw==; ali_apache_id=33.1.233.210.1669256184316.569493.2; intl_locale=es_ES; cna=+sEFHEWkrHICAbqbhd2ZxuSR; _gid=GA1.2.749679866.1669256188; _gac_UA-17640202-1=1.1669256188.CjwKCAiApvebBhAvEiwAe7mHSGDdjIt-FP4DEcl4R7wgt2qOmzrb6L4hx7iMS6yUI7FudKbj9rZnexoCEEAQAvD_BwE; xlly_s=1; _gcl_aw=GCL.1669256188.CjwKCAiApvebBhAvEiwAe7mHSGDdjIt-FP4DEcl4R7wgt2qOmzrb6L4hx7iMS6yUI7FudKbj9rZnexoCEEAQAvD_BwE; _gcl_dc=GCL.1669256188.CjwKCAiApvebBhAvEiwAe7mHSGDdjIt-FP4DEcl4R7wgt2qOmzrb6L4hx7iMS6yUI7FudKbj9rZnexoCEEAQAvD_BwE; _gcl_au=1.1.1346632231.1669256188; _fbp=fb.1.1669256187874.1553598377; _ym_uid=1669256189713719043; _ym_d=1669256189; _ym_isad=2; ali_apache_track=; ali_apache_tracktmp=; e_id=pt60; XSRF-TOKEN=523a85a2-a51e-4432-94c5-f12b7d10e88b; account_v=1; aep_usuc_f=site=esp&c_tp=COP&region=CO&b_locale=es_ES; AKA_A2=A; xman_us_f=x_locale=es_ES&x_l=0&x_c_chg=0&x_as_i=%7B%22aeuCID%22%3A%226afa8bad078e42a0ba2674ea27a0dc7f-1669256183899-05653-UneMJZVf%22%2C%22affiliateKey%22%3A%22UneMJZVf%22%2C%22channel%22%3A%22PREMINUM%22%2C%22cv%22%3A%222%22%2C%22isCookieCache%22%3A%22N%22%2C%22ms%22%3A%221%22%2C%22pid%22%3A%22178094261%22%2C%22tagtime%22%3A1669256183899%7D&acs_rt=bc33d50efba94b6fb9b8abfdd1ed9ba6; _m_h5_tk=ad7ce0544cae0218ad4f655cae989b47_1669268185710; _m_h5_tk_enc=da927f18e91f29767539ef4469a4bb60; aep_history=keywords%5E%0Akeywords%09%0A%0Aproduct_selloffer%5E%0Aproduct_selloffer%091005003932740121%091005004430757538%091005004448609411; _ym_visorc=b; _gat=1; _ga=GA1.1.276904634.1669256188; RT=\"z=1&dm=aliexpress.com&si=7be28f9c-9c31-4e03-bcbb-f2c03a5f223c&ss=laumgnum&sl=1&tt=1xt&rl=1&ld=1xv\"; JSESSIONID=3D5912BBF3584A85FD8A9F8CDE618A0A; intl_common_forever=oIKdtXaeB7roRyvuv01SfF+3pJQVNbtcTl6z0Tneo9PCfzRKKrVC1A==; _ga_VED1YSGNC7=GS1.1.1669266387.3.1.1669266997.0.0.0; l=eBMP6WIqTBp0yszFBO5wlurza77OyQvfGsPzaNbMiInca6GAtpPTHNCU8sQvSdtjQtfhqetPgOBNgd3681zdgimiTHhHz852MYvM-; tfstk=cTDNBAXAEdpZBVmvyJ2qU424e_POayMmFCEYsEf0YSxWoUVgzsYGkkAk-V3VYZVG.; isg=BHt7DPj9nPyHKaBIjpIDngPsGl_l0I_Sdv4q9206Z3ujzJ-u9aHZIvVK5nSCbOfK',\n",
    "            'referer': urlRaw,\n",
    "            'sec-ch-ua': '\"Chromium\";v=\"106\", \"Not.A/Brand\";v=\"24\", \"Opera GX\";v=\"92\"',\n",
    "            'sec-ch-ua-mobile': '?0',\n",
    "            'sec-ch-ua-platform': '\"Windows\"',\n",
    "            'sec-fetch-dest': 'empty',\n",
    "            'sec-fetch-mode': 'cors',\n",
    "            'sec-fetch-site': 'same-origin',\n",
    "            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/106.0.0.0 Safari/537.36 OPR/92.0.0.0'\n",
    "        }\n",
    "        return urlRaw, requests.request(\n",
    "            \"GET\", url, headers = headers, params = query_string_parameters\n",
    "        )\n",
    "    def searchElement(self, json, key):\n",
    "        if key == 'Rating':\n",
    "            try:\n",
    "                return json['evaluation']['starRating']\n",
    "            except KeyError:\n",
    "                return np.nan\n",
    "        elif key == 'Selling':\n",
    "            try:\n",
    "                lista = json['sellingPoints']\n",
    "                flag = 0\n",
    "                for i in range(0, len(lista)):\n",
    "                    try:\n",
    "                        flag += 1 if lista[i]['tagContent']['tagText'] == 'Envío gratis' else 0\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                return True if flag > 0 else False\n",
    "            except KeyError:\n",
    "                return False\n",
    "        elif key == 'Trade':\n",
    "            try:\n",
    "                return int(json['trade']['tradeDesc'].replace(' vendido(s)', ''))\n",
    "            except KeyError:\n",
    "                return np.nan\n",
    "    def getValues(self, dict):\n",
    "        rows = dict['mods']['itemList']['content']\n",
    "        Products = []\n",
    "        for i in range(0, len(rows)):\n",
    "            ID     = rows[i]['productId']\n",
    "            Rating = self.searchElement(rows[i], key = 'Rating')\n",
    "            Trade  = self.searchElement(rows[i], key = 'Trade')\n",
    "            Envio  = self.searchElement(rows[i], key = 'Selling')\n",
    "            Titulo = rows[i]['title']['displayTitle']\n",
    "            Precio = float(rows[i]['prices']['salePrice']['formattedPrice'].replace('COP ', '').replace(',', ''))\n",
    "            URL    = 'https://es.aliexpress.com/item/'+rows[i]['productId']+'.html'\n",
    "            Products.append((ID, URL, Titulo, Precio, Rating, Trade, Envio))\n",
    "        return Products\n",
    "    def createDF(self, list):\n",
    "        df = pd.DataFrame(list, columns = ['ID', 'URL', 'Producto', 'Precio', 'Ranting', 'Vendidos', 'EnvíoGratis'])\n",
    "        df['Origen'] = \"AliExpress\"\n",
    "        df.to_csv('Support Files/AliExpress.csv', index = False)\n",
    "        df.to_csv('Support Files/AliExpress.txt', sep = '|', index = False)\n",
    "        return df\n",
    "    def controller(self):\n",
    "        Values = []\n",
    "        j = 1\n",
    "        while True:\n",
    "            Website, Result = self.getConnection(self.cleanPath(), j)\n",
    "            if Result.status_code == 200:\n",
    "                print(Website)\n",
    "                Content = Result.json()\n",
    "                try:\n",
    "                    Info = self.getValues(Content)\n",
    "                    Values.extend(Info)\n",
    "                    if len(Values) >= int(self.limit):\n",
    "                        Values = Values[:self.limit]\n",
    "                        return self.createDF(Values)\n",
    "                    else:\n",
    "                        j += 1\n",
    "                except KeyError:\n",
    "                    Values = []\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"Sin respuesta por parte del servidor. Fallo al tratar de visitar la página web:\\n\\t--> {Website}\"\n",
    "                )\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## **CONSOLIDADO DE RESULTADOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Página Número: 1 | Link: https://www.easy.com.co/c/herramientas/herramientas-para-madera/lijadoras/\n",
      "https://www.homecenter.com.co/homecenter-co/category/cat300032/lijadoras-electricas-y-accesorios/\n",
      "Página Número: 1 | Link: https://www.homecenter.com.co/homecenter-co/category/cat300032/lijadoras-electricas-y-accesorios/\n",
      "Página Número: 2 | Link: https://www.homecenter.com.co/homecenter-co/category/cat300032/lijadoras-electricas-y-accesorios?currentpage=2\n",
      "Página Número: 3 | Link: https://www.homecenter.com.co/homecenter-co/category/cat300032/lijadoras-electricas-y-accesorios?currentpage=3\n",
      "Página Número: 4 | Link: https://www.homecenter.com.co/homecenter-co/category/cat300032/lijadoras-electricas-y-accesorios?currentpage=4\n",
      "Página Número: 5 | Link: https://www.homecenter.com.co/homecenter-co/category/cat300032/lijadoras-electricas-y-accesorios?currentpage=5\n",
      "Página Número: 6 | Link: https://www.homecenter.com.co/homecenter-co/category/cat300032/lijadoras-electricas-y-accesorios?currentpage=6\n",
      "Visitando la Página Número: 1 de 40\n",
      "Link: https://listado.mercadolibre.com.co/lijadora\n",
      "https://es.aliexpress.com/wholesale?trafficChannel=ppc&d=y&CatId=0&SearchText=lijadora&ltype=premium&SortType=default&page=1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Origen</th>\n",
       "      <th>ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Producto</th>\n",
       "      <th>Precio</th>\n",
       "      <th>Categoria</th>\n",
       "      <th>Ranting</th>\n",
       "      <th>Vendidos</th>\n",
       "      <th>EnvíoGratis</th>\n",
       "      <th>HoraEjecución</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Easy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.easy.com.co/p/lijadora-orbital-ina...</td>\n",
       "      <td>Lijadora Orbital Inalambrica 24000 Opm</td>\n",
       "      <td>299.990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14/01/2023 23:16:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Easy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.easy.com.co/p/lijadora-triangular-...</td>\n",
       "      <td>Lijadora Triangular Inalambrica 24000 (Solo Eq...</td>\n",
       "      <td>188.990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14/01/2023 23:16:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Easy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.easy.com.co/p/lijadora-stel401-orb...</td>\n",
       "      <td>Lijadora STEL401 Orbital 220W 16000rpm</td>\n",
       "      <td>237.900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14/01/2023 23:16:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Easy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.easy.com.co/p/lijadora-1~3-de-150-...</td>\n",
       "      <td>Lijadora 1/3 de 150 W de Potencia</td>\n",
       "      <td>119.990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14/01/2023 23:16:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Easy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.easy.com.co/p/lijadora-dwe6421-pal...</td>\n",
       "      <td>Lijadora DWE6421 Palma Orbital 280w 12000opm</td>\n",
       "      <td>614.900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14/01/2023 23:16:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AliExpress</td>\n",
       "      <td>1005003217998748</td>\n",
       "      <td>https://es.aliexpress.com/item/100500321799874...</td>\n",
       "      <td>HYVST-LIJADORA Orbital aleatoria multifunción ...</td>\n",
       "      <td>814146.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.9</td>\n",
       "      <td>168.0</td>\n",
       "      <td>False</td>\n",
       "      <td>14/01/2023 23:16:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AliExpress</td>\n",
       "      <td>1005004296565077</td>\n",
       "      <td>https://es.aliexpress.com/item/100500429656507...</td>\n",
       "      <td>Máquina pulidora de belleza para coche, lijado...</td>\n",
       "      <td>268830.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>True</td>\n",
       "      <td>14/01/2023 23:16:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AliExpress</td>\n",
       "      <td>1005005120508701</td>\n",
       "      <td>https://es.aliexpress.com/item/100500512050870...</td>\n",
       "      <td>LIJADORA Orbital neumática de pulgadas, amolad...</td>\n",
       "      <td>246109.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>14/01/2023 23:16:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AliExpress</td>\n",
       "      <td>1005003994256463</td>\n",
       "      <td>https://es.aliexpress.com/item/100500399425646...</td>\n",
       "      <td>Mini lijadora de 110V-220V, 18W, modelo de máq...</td>\n",
       "      <td>112363.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>False</td>\n",
       "      <td>14/01/2023 23:16:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AliExpress</td>\n",
       "      <td>32973184325</td>\n",
       "      <td>https://es.aliexpress.com/item/32973184325.html</td>\n",
       "      <td>PROSTORMER-Lijadora orbital aleatoria de 300W,...</td>\n",
       "      <td>301310.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.9</td>\n",
       "      <td>199.0</td>\n",
       "      <td>False</td>\n",
       "      <td>14/01/2023 23:16:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Origen                ID  \\\n",
       "0         Easy               NaN   \n",
       "1         Easy               NaN   \n",
       "2         Easy               NaN   \n",
       "3         Easy               NaN   \n",
       "4         Easy               NaN   \n",
       "..         ...               ...   \n",
       "5   AliExpress  1005003217998748   \n",
       "6   AliExpress  1005004296565077   \n",
       "7   AliExpress  1005005120508701   \n",
       "8   AliExpress  1005003994256463   \n",
       "9   AliExpress       32973184325   \n",
       "\n",
       "                                                  URL  \\\n",
       "0   https://www.easy.com.co/p/lijadora-orbital-ina...   \n",
       "1   https://www.easy.com.co/p/lijadora-triangular-...   \n",
       "2   https://www.easy.com.co/p/lijadora-stel401-orb...   \n",
       "3   https://www.easy.com.co/p/lijadora-1~3-de-150-...   \n",
       "4   https://www.easy.com.co/p/lijadora-dwe6421-pal...   \n",
       "..                                                ...   \n",
       "5   https://es.aliexpress.com/item/100500321799874...   \n",
       "6   https://es.aliexpress.com/item/100500429656507...   \n",
       "7   https://es.aliexpress.com/item/100500512050870...   \n",
       "8   https://es.aliexpress.com/item/100500399425646...   \n",
       "9     https://es.aliexpress.com/item/32973184325.html   \n",
       "\n",
       "                                             Producto     Precio Categoria  \\\n",
       "0              Lijadora Orbital Inalambrica 24000 Opm    299.990       NaN   \n",
       "1   Lijadora Triangular Inalambrica 24000 (Solo Eq...    188.990       NaN   \n",
       "2              Lijadora STEL401 Orbital 220W 16000rpm    237.900       NaN   \n",
       "3                   Lijadora 1/3 de 150 W de Potencia    119.990       NaN   \n",
       "4        Lijadora DWE6421 Palma Orbital 280w 12000opm    614.900       NaN   \n",
       "..                                                ...        ...       ...   \n",
       "5   HYVST-LIJADORA Orbital aleatoria multifunción ...  814146.39       NaN   \n",
       "6   Máquina pulidora de belleza para coche, lijado...  268830.95       NaN   \n",
       "7   LIJADORA Orbital neumática de pulgadas, amolad...  246109.47       NaN   \n",
       "8   Mini lijadora de 110V-220V, 18W, modelo de máq...  112363.68       NaN   \n",
       "9   PROSTORMER-Lijadora orbital aleatoria de 300W,...   301310.7       NaN   \n",
       "\n",
       "    Ranting  Vendidos EnvíoGratis        HoraEjecución  \n",
       "0       NaN       NaN         NaN  14/01/2023 23:16:53  \n",
       "1       NaN       NaN         NaN  14/01/2023 23:16:53  \n",
       "2       NaN       NaN         NaN  14/01/2023 23:16:53  \n",
       "3       NaN       NaN         NaN  14/01/2023 23:16:53  \n",
       "4       NaN       NaN         NaN  14/01/2023 23:16:53  \n",
       "..      ...       ...         ...                  ...  \n",
       "5       4.9     168.0       False  14/01/2023 23:16:53  \n",
       "6       5.0      22.0        True  14/01/2023 23:16:53  \n",
       "7       NaN       NaN       False  14/01/2023 23:16:53  \n",
       "8       5.0     148.0       False  14/01/2023 23:16:53  \n",
       "9       4.9     199.0       False  14/01/2023 23:16:53  \n",
       "\n",
       "[178 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r'D:\\Documentos\\JOBS\\DNPE\\DocumentosDNPE\\Web Scraping')\n",
    "\n",
    "dfAll = pd.DataFrame(columns = [\n",
    "    'Origen', 'ID', 'URL', 'Producto', 'Precio', 'Categoria',\n",
    "    'Ranting', 'Vendidos', 'EnvíoGratis'\n",
    "    ]\n",
    ")\n",
    "\n",
    "dfAll = pd.concat(\n",
    "    [dfAll,\n",
    "     WebScrapingEasy('Herramientas > Herramientas para Madera > Lijadoras').controller(),\n",
    "     WebScrapingHomeCenter('Herramientas y Maquinarias > Herramientas Eléctricas e Inalámbricas > Lijadoras Eléctricas y Accesorios').controller(),\n",
    "     WebScrapingMercadoLibre('lijadora', limit = 14, infoExtra = True).controller(),\n",
    "     WebScrapingAliExpress('lijadora', limit = 10).controller()\n",
    "    ], axis = 0)\n",
    "\n",
    "dfAll['HoraEjecución'] = (datetime.now()).strftime('%d/%m/%Y %H:%M:%S')\n",
    "dfAll.to_csv('Code/Consolidado.csv', index = False)\n",
    "dfAll"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
